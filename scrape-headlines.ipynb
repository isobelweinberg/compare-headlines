{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Run this notebook to add some headlines to scraped data\n",
    "###i.e. this script is for UPDATING existing tables of headlines with today's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Import necessaries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import sqlite3\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Open database\n",
    "conn = sqlite3.connect(r'C:\\xampp\\htdocs\\compare-editorial-line\\headlines.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##GUARDIAN\n",
    "##Get data\n",
    "r = urllib.request.urlopen('https://www.theguardian.com/uk').read() #get html\n",
    "soup = BeautifulSoup(r, \"lxml\") #run html through beautiful soup\n",
    "#print(soup) #to look at html\n",
    "today = datetime.date.today() #Store date and time\n",
    "now = datetime.datetime.now() #time = datetime.datetime.now().time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Save data\n",
    "#soup.find_all(\"a\", class_=\"fc-item__link\")\n",
    "headlines = soup.find_all(\"span\", class_=\"js-headline-text\") #get all headlines on page\n",
    "\n",
    "currentlength = c.execute(\"SELECT COUNT(*) FROM guardian\").fetchall() #find out how long existing database is, so can add to it\n",
    "currentlength = currentlength[0]\n",
    "currentlength = currentlength[0] #yes you need it twice! tuple inside list\n",
    "\n",
    "id = currentlength #start from previous last row\n",
    "for h in headlines:\n",
    "    #print(h.get_text())\n",
    "    id += 1\n",
    "    c.execute(\"INSERT INTO guardian VALUES(?, ?, ?, ?, '')\", (id, today, now, h.get_text())) #store in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##If need to have a look\n",
    "#for row in c.execute(\"SELECT * FROM guardian\"):\n",
    "   #print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Repeat for BBC NEWS\n",
    "##Get data\n",
    "bbc_r = urllib.request.urlopen('http://www.bbc.co.uk/news/uk').read()\n",
    "bbc_soup = BeautifulSoup(bbc_r, \"lxml\")\n",
    "bbc_today = datetime.date.today()\n",
    "bbc_now = datetime.datetime.now()\n",
    "#print(bbc_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Save data\n",
    "main = bbc_soup.div(class_=\"buzzard-item\")\n",
    "medium = bbc_soup.div(class_=\"pigeon-item__body\")\n",
    "small = bbc_soup.div(class_=\"pigeon__column pigeon__column--b\")\n",
    "tiny = bbc_soup.div(class_=\"macaw-item__body\")\n",
    "bbc_divs = main + medium + small + tiny\n",
    "bbc_headlines = None\n",
    "\n",
    "# Create table\n",
    "currentlength = c.execute(\"SELECT COUNT(*) FROM BBCnews\").fetchall() #find out how long existing database is, so can add to it\n",
    "currentlength = currentlength[0]\n",
    "currentlength = currentlength[0] #yes you need it twice! tuple inside list\n",
    "\n",
    "id = currentlength #preallocate\n",
    "for div in bbc_divs:\n",
    "    headlines = div.find_all(\"span\", class_=\"title-link__title-text\")\n",
    "    for h in headlines:\n",
    "        #print(h.get_text())\n",
    "        id += 1\n",
    "        c.execute(\"INSERT INTO BBCnews VALUES(?, ?, ?, ?, '')\", (id, bbc_today, bbc_now, h.get_text()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Repeat for DAILY MAIL\n",
    "##Get data\n",
    "dm_r = urllib.request.urlopen('http://www.dailymail.co.uk/home/index.html').read()\n",
    "dm_soup = BeautifulSoup(dm_r, \"lxml\")\n",
    "dm_today = datetime.date.today()\n",
    "dm_now = datetime.datetime.now()\n",
    "#print(dm_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Save data\n",
    "headlines = dm_soup.find_all(class_=\"linkro-darkred\")\n",
    "\n",
    "# Create table\n",
    "currentlength = c.execute(\"SELECT COUNT(*) FROM dailymail\").fetchall() #find out how long existing database is, so can add to it\n",
    "currentlength = currentlength[0]\n",
    "currentlength = currentlength[0] #yes you need it twice! tuple inside list\n",
    "\n",
    "id = currentlength #preallocate\n",
    "for h in headlines:\n",
    "    htxt = h.get_text()\n",
    "    htxt = htxt.strip('\\n')\n",
    "    htxt = htxt.strip('\\xa0')\n",
    "    htxt = htxt.replace('\\n','')\n",
    "    id += 1\n",
    "    #print(htxt)\n",
    "    c.execute(\"INSERT INTO dailymail VALUES(?, ?, ?, ?, '')\", (id, dm_today, dm_now, htxt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Commit to database and close connection\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f20b7793ebea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM dailymail\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "for row in c.execute(\"SELECT * FROM dailymail\"):\n",
    "   print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in c.execute(\"SELECT * FROM guardian\"):\n",
    "   print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in c.execute(\"SELECT * FROM BBCnews\"):\n",
    "   print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
